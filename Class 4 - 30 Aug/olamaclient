from ollama import Client

def get_ollama_client(host='http://localhost:11434'):
    client = Client(host=host)
    return client

if __name__ == '__main__':
    client = get_ollama_client()
    response = client.chat(model='gemma2:2b', messages = 
            [{
                'role': 'user',
                'content': 'Why is sky blue?',
            },
            ])
    

    print(response['message']['content'])

    response = client.generate(model='gemma2:2b', prompt='tell me about deep learning')
    print(response["response"])